{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQXkecSdR7Ix",
    "outputId": "bbea21a0-b52c-4edc-80d7-0754e2d4d190"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m greycomatrix, greycoprops\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import io\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from skimage.measure import shannon_entropy\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbj2mDvMbLsg"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVw37TyCR7I2"
   },
   "outputs": [],
   "source": [
    "#Training Set\n",
    "'''image_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/OriginalImages/TrainingSet/\"\n",
    "EX_mask_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Groundtruths/TrainingSet/HardExudates/\"\n",
    "SE_mask_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Groundtruths/TrainingSet/SoftExudates/\"\n",
    "candidates_path =\"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Candidates/Exudates/\"\n",
    "\n",
    "images = os.listdir(image_path)\n",
    "EX_masks = os.listdir(EX_mask_path)\n",
    "SE_masks = os.listdir(SE_mask_path)\n",
    "\n",
    "images.sort()\n",
    "EX_masks.sort()\n",
    "SE_masks.sort()\n",
    "'''\n",
    "scaler_filename = \"/content/drive/MyDrive/DRsegmentation/IP_ML/Training/EX_scaler.save\"\n",
    "\n",
    "#Test\n",
    "image_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/OriginalImages/TestingSet/\"\n",
    "EX_mask_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Groundtruths/TestingSet/HardExudates/\"\n",
    "SE_mask_path = \"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Groundtruths/TestingSet/SoftExudates/\"\n",
    "candidates_path =\"/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/Candidates/TestSet/Exudates/\"\n",
    "\n",
    "images = os.listdir(image_path)\n",
    "EX_masks = os.listdir(EX_mask_path)\n",
    "SE_masks = os.listdir(SE_mask_path)\n",
    "\n",
    "images.sort()\n",
    "EX_masks.sort()\n",
    "SE_masks.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDZDJnHJR7I3"
   },
   "outputs": [],
   "source": [
    "def rgb2Gray(img):\n",
    "    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def clahe_equalized(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl1 = clahe.apply(img)\n",
    "    return  cl1\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "   table = np.array([((i / 255.0) ** gamma) * 255\n",
    "      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "   return cv2.LUT(image, table)\n",
    "\n",
    "def OTSU(img_gray):\n",
    "    max_g = 0\n",
    "    suitable_th = 0\n",
    "    th_begin = 0\n",
    "    th_end = 256\n",
    "    for threshold in range(th_begin, th_end):\n",
    "        bin_img = img_gray > threshold\n",
    "        bin_img_inv = img_gray <= threshold\n",
    "        fore_pix = np.sum(bin_img)\n",
    "        back_pix = np.sum(bin_img_inv)\n",
    "        if 0 == fore_pix:\n",
    "            break\n",
    "        if 0 == back_pix:\n",
    "            continue\n",
    " \n",
    "        w0 = float(fore_pix) / img_gray.size\n",
    "        u0 = float(np.sum(img_gray * bin_img)) / fore_pix\n",
    "        w1 = float(back_pix) / img_gray.size\n",
    "        u1 = float(np.sum(img_gray * bin_img_inv)) / back_pix\n",
    "        # intra-class variance\n",
    "        g = w0 * w1 * (u0 - u1) * (u0 - u1)\n",
    "        if g > max_g:\n",
    "            max_g = g\n",
    "            suitable_th = threshold\n",
    " \n",
    "    return suitable_th\n",
    "\n",
    "\n",
    "def vessel(img):\n",
    "    dst = 255 - img\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.18,tileGridSize=(1,1))\n",
    "    Ien = clahe.apply(dst)  \n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(15,15))\n",
    "    opening = cv2.morphologyEx(dst, cv2.MORPH_OPEN, kernel)\n",
    "    final = cv2.subtract(Ien,opening)\n",
    "    test =  OTSU(final)\n",
    "    ret , binary = cv2.threshold (final ,test, test, cv2.THRESH_BINARY) \n",
    "    binary = cv2.medianBlur(binary, 3) \n",
    "    #binary = cv2.blur(binary,(5,5))\n",
    "    return binary\n",
    "\n",
    "\n",
    "def evaluation(image, mask):\n",
    "    \n",
    "    zeros_list_img, one_list_img, zeros_list_mk, one_list_mk = [], [], [], []\n",
    "    \n",
    "    for i in range(0,image.shape[0]):\n",
    "        for j in range(0,image.shape[1]):\n",
    "            val_mk = mask[i][j]\n",
    "            val_img  = image[i][j]\n",
    "            if val_mk == 0:\n",
    "                zeros_list_mk.append((i,j))\n",
    "            else:\n",
    "                one_list_mk.append((i,j))\n",
    "            if val_img == 0:\n",
    "                zeros_list_img.append((i,j))\n",
    "            else:\n",
    "                one_list_img.append((i,j))\n",
    "    TP = len(set(one_list_img).intersection(set(one_list_mk)))\n",
    "    #TN = len(set(zeros_list_img).intersection(set(zeros_list_mk)))\n",
    "    #FP = len(set(one_list_img).intersection(set(zeros_list_mk)))\n",
    "    FN = len(set(zeros_list_img).intersection(set(one_list_mk)))\n",
    "    #TPR = TP/(FN + TP)\n",
    "    #TNR = TN/(TN + FP)\n",
    "    #P = TP/(TP + FP)\n",
    "    R=0\n",
    "    if (TP+FN) !=0: \n",
    "      R = TP/(TP + FN)\n",
    "    #JSC = TP/(TP + FP + FN)\n",
    "    #DSC = 2*(TP/(FP + 2*TP + FN))\n",
    "    return R\n",
    "\n",
    "\n",
    "\n",
    "def feature_extractor(region):\n",
    "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
    "        #Reset dataframe to blank after each loop.\n",
    "        \n",
    "        ################################################################\n",
    "        #START ADDING DATA TO THE DATAFRAME\n",
    "  \n",
    "                \n",
    "        #Full image\n",
    "        #GLCM = greycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "        GLCM = greycomatrix(region, [1], [0])       \n",
    "        GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n",
    "        df['Energy'] = GLCM_Energy\n",
    "        GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n",
    "        df['Corr'] = GLCM_corr       \n",
    "        GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n",
    "        df['Diss_sim'] = GLCM_diss       \n",
    "        GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n",
    "        df['Homogen'] = GLCM_hom       \n",
    "        GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n",
    "        df['Contrast'] = GLCM_contr\n",
    "\n",
    "\n",
    "        GLCM2 = greycomatrix(region, [3], [0])       \n",
    "        GLCM_Energy2 = greycoprops(GLCM2, 'energy')[0]\n",
    "        df['Energy2'] = GLCM_Energy2\n",
    "        GLCM_corr2 = greycoprops(GLCM2, 'correlation')[0]\n",
    "        df['Corr2'] = GLCM_corr2       \n",
    "        GLCM_diss2 = greycoprops(GLCM2, 'dissimilarity')[0]\n",
    "        df['Diss_sim2'] = GLCM_diss2       \n",
    "        GLCM_hom2 = greycoprops(GLCM2, 'homogeneity')[0]\n",
    "        df['Homogen2'] = GLCM_hom2       \n",
    "        GLCM_contr2 = greycoprops(GLCM2, 'contrast')[0]\n",
    "        df['Contrast2'] = GLCM_contr2\n",
    "\n",
    "        GLCM3 = greycomatrix(region, [5], [0])       \n",
    "        GLCM_Energy3 = greycoprops(GLCM3, 'energy')[0]\n",
    "        df['Energy3'] = GLCM_Energy3\n",
    "        GLCM_corr3 = greycoprops(GLCM3, 'correlation')[0]\n",
    "        df['Corr3'] = GLCM_corr3       \n",
    "        GLCM_diss3 = greycoprops(GLCM3, 'dissimilarity')[0]\n",
    "        df['Diss_sim3'] = GLCM_diss3       \n",
    "        GLCM_hom3 = greycoprops(GLCM3, 'homogeneity')[0]\n",
    "        df['Homogen3'] = GLCM_hom3       \n",
    "        GLCM_contr3 = greycoprops(GLCM3, 'contrast')[0]\n",
    "        df['Contrast3'] = GLCM_contr3\n",
    "\n",
    "        GLCM4 = greycomatrix(region, [0], [np.pi/4])       \n",
    "        GLCM_Energy4 = greycoprops(GLCM4, 'energy')[0]\n",
    "        df['Energy4'] = GLCM_Energy4\n",
    "        GLCM_corr4 = greycoprops(GLCM4, 'correlation')[0]\n",
    "        df['Corr4'] = GLCM_corr4       \n",
    "        GLCM_diss4 = greycoprops(GLCM4, 'dissimilarity')[0]\n",
    "        df['Diss_sim4'] = GLCM_diss4       \n",
    "        GLCM_hom4 = greycoprops(GLCM4, 'homogeneity')[0]\n",
    "        df['Homogen4'] = GLCM_hom4       \n",
    "        GLCM_contr4 = greycoprops(GLCM4, 'contrast')[0]\n",
    "        df['Contrast4'] = GLCM_contr4\n",
    "        \n",
    "        GLCM5 = greycomatrix(region, [0], [np.pi/2])       \n",
    "        GLCM_Energy5 = greycoprops(GLCM5, 'energy')[0]\n",
    "        df['Energy5'] = GLCM_Energy5\n",
    "        GLCM_corr5 = greycoprops(GLCM5, 'correlation')[0]\n",
    "        df['Corr5'] = GLCM_corr5       \n",
    "        GLCM_diss5 = greycoprops(GLCM5, 'dissimilarity')[0]\n",
    "        df['Diss_sim5'] = GLCM_diss5       \n",
    "        GLCM_hom5 = greycoprops(GLCM5, 'homogeneity')[0]\n",
    "        df['Homogen5'] = GLCM_hom5       \n",
    "        GLCM_contr5 = greycoprops(GLCM5, 'contrast')[0]\n",
    "        df['Contrast5'] = GLCM_contr5\n",
    "        \n",
    "        #Add more filters as needed\n",
    "        entropy = shannon_entropy(region)\n",
    "        df['Entropy'] = entropy\n",
    "\n",
    "        \n",
    "        #Append features from current image to the dataset\n",
    "        #image_dataset = image_dataset.append(df)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "def candidates_selection(rimg,im_mask_ex,im_mask_se):\n",
    "    contours, hierarchy = cv2.findContours(rimg,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    idx =0 \n",
    "    t_features = pd.DataFrame()\n",
    "    t_labels = [] \n",
    "    print(len(contours))\n",
    "    for cnt in contours:\n",
    "        idx += 1\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        roi=rimg[y:y+h,x:x+w]\n",
    "        cv2.rectangle(originalImage,(x,y),(x+w,y+h),(0,255,255),5)\n",
    "        regions_img=rimg[y:y+h, x:x+w]\n",
    "        regions_ex=im_mask_ex[y:y+h, x:x+w]\n",
    "        regions_se=im_mask_se[y:y+h, x:x+w]\n",
    "        S_ex = evaluation(regions_img, regions_ex)\n",
    "        S_se = evaluation(regions_img, regions_se)\n",
    "        t_features=t_features.append(feature_extractor(cv2.cvtColor(img[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)))\n",
    "        if (S_ex > 0.1) and (S_ex >= S_se):\n",
    "           t_labels.append(1)\n",
    "        elif (S_se>0.1) and (S_se >= S_ex):\n",
    "          t_labels.append(2)\n",
    "        else:\n",
    "          t_labels.append(0)\n",
    "\n",
    "    return t_features, t_labels\n",
    "\n",
    "def candidates_extraction_for_inference(mymodel,imgorginal,rimg):\n",
    "    contours, hierarchy = cv2.findContours(rimg,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    idx =0 \n",
    "    region_features = [] \n",
    "    preds0=[]\n",
    "    preds1=[]\n",
    "    ex_segmented_img = np.zeros((imgorginal.shape[0],imgorginal.shape[1])) \n",
    "    for cnt in contours:\n",
    "        idx += 1\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        region_features = pd.DataFrame()\n",
    "        region_features=feature_extractor(cv2.cvtColor(imgorginal[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY))\n",
    "        scaler = joblib.load(scaler_filename) \n",
    "        features=scaler.transform(region_features.values)\n",
    "        pred= mymodel.predict(features)\n",
    "        if pred[0]==1:\n",
    "          preds0.append(pred[0])\n",
    "          ex_segmented_img[y:y+h, x:x+w] = rimg[y:y+h, x:x+w]\n",
    "    return preds0, preds1, ex_segmented_img\n",
    "\n",
    "def plot(myimg,mtype=\"gray\"):\n",
    "  if mtype==\"gray\":\n",
    "    plt.imshow(myimg,cmap= mtype)\n",
    "  else:\n",
    "    plt.imshow(cv2.cvtColor(myimg, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()\n",
    "\n",
    "def train(classifier,X_train,y_train):\n",
    "    if classifier=='LGBM':\n",
    "        #Class names for LGBM start at 0 so reassigning labels from 1,2,3,4 to 0,1,2,3\n",
    "        d_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "        # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "        lgbm_params = {'learning_rate':0.05, 'boosting_type':'dart',    \n",
    "                       'objective':'multiclass',\n",
    "                       'metric': 'multi_logloss',\n",
    "                       'num_leaves':100,\n",
    "                       'max_depth':10,\n",
    "                       'num_class':3}  #no.of unique values in the target class not inclusive of the end value\n",
    "        my_model = lgb.train(lgbm_params, d_train, 100) #50 iterations. Increase iterations for small learning rates\n",
    "    elif  classifier=='RF':\n",
    "        my_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "        my_model.fit(X_train, y_train) \n",
    "    elif classifier=='SVM':\n",
    "        #my_model = svm.SVC(decision_function_shape='ovo')  #For multiclass classification\n",
    "        #my_model.fit(X_train, y_train)\n",
    "        my_model = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "        #my_model = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "\n",
    "    return my_model\n",
    "\n",
    "def predict(mymodel,X_test,y_test):\n",
    "  test_prediction = mymodel.predict(X_test)\n",
    "  test_pred = (test_prediction >= 0.5)\n",
    "  acc=metrics.accuracy_score(y_test, test_pred)\n",
    "  df = pd.DataFrame()\n",
    "  y_test = np.array(y_test)\n",
    "  y_test = y_test.flatten()\n",
    "  df['y_test'] = y_test\n",
    "  df['test_pred'] = test_pred\n",
    "  writer = ExcelWriter('/content/drive/MyDrive/DRsegmentation/IP_ML/Training/acc_exudates_test.xlsx')\n",
    "  df.to_excel(writer,'Sheet5')\n",
    "  writer.save()\n",
    "  return acc,test_pred\n",
    "\n",
    "#Print confusion matrix\n",
    "def CM_plot(y_test, test_pred):\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))         # Sample figsize in inches\n",
    "    sns.set(font_scale=1.6)\n",
    "    sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n",
    "\n",
    "def extract_Exudates(img):\n",
    "    gray  = rgb2Gray(img)\n",
    "    T, B_Fov = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    b,g,r = cv2.split(img)\n",
    "    Ienhance = clahe_equalized(g)\n",
    "    Ienhance =adjust_gamma((255-Ienhance),gamma=1)\n",
    "    plt.imshow(Ienhance,\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    Imedfilter = cv2.medianBlur(Ienhance,81)\n",
    "    Isub = cv2.subtract(Imedfilter,Ienhance)\n",
    "    Isub_filter = cv2.blur(Isub,(5,5))\n",
    "    Isub_filter = cv2.bitwise_and(Isub,B_Fov)\n",
    "    bestTh = OTSU(Isub_filter)\n",
    "    T,Idark_tep = cv2.threshold(Isub_filter, bestTh, 255, cv2.THRESH_BINARY)\n",
    "    sOP = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2,2))\n",
    "    Bdark = cv2.morphologyEx(Idark_tep,cv2.MORPH_OPEN,sOP)\n",
    "\n",
    "    Imed = cv2.medianBlur(Ienhance,131)\n",
    "    Isub1 = cv2.subtract(Imed,Ienhance)\n",
    "    Isub_filter1 = cv2.blur(Isub1,(5,5))\n",
    "    bestTh1 =  OTSU(Isub_filter1)\n",
    "    T,Idark_tep1 = cv2.threshold(Isub_filter1, bestTh1, 255, cv2.THRESH_BINARY)\n",
    "    Bdark1 = cv2.morphologyEx(Idark_tep1,cv2.MORPH_OPEN,sOP)\n",
    "\n",
    "    Bduel = cv2.bitwise_or(Bdark,Bdark1)\n",
    "\n",
    "    Ismooth = cv2.GaussianBlur(Ienhance,(7,7),0)\n",
    "    Ivessel = vessel(Ismooth)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    Ivessel = cv2.dilate(Ivessel, kernel)\n",
    "\n",
    "    Bduel = cv2.erode(Bduel,kernel)\n",
    "    same = cv2.bitwise_and(Ivessel,Bduel)\n",
    "    result = cv2.subtract(Bduel,same)\n",
    "    sOP6 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(6,6))\n",
    "    result = cv2.morphologyEx(result,cv2.MORPH_OPEN,sOP6)\n",
    "    result = cv2.erode(result,kernel)\n",
    "\n",
    "    sOP10 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10,10))\n",
    "    result1 = cv2.morphologyEx(result,cv2.MORPH_OPEN,sOP10)\n",
    "\n",
    "    result = cv2.bitwise_or(result,result1)\n",
    "    result =  cv2.dilate(result, kernel)\n",
    "    return result\n",
    "\n",
    "def segment(original_img,segmented_img):\n",
    "  #\n",
    "  rf=candidates_extraction_for_inference(mymodel,original_img,segmented_img)\n",
    "\n",
    "  return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "74JP1L1bLLA5",
    "outputId": "ccb00d58-4a2f-40d9-c32b-73bcf748134c"
   },
   "outputs": [],
   "source": [
    "#original_img= cv2.imread('/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/OriginalImages/TestingSet/IDRiD_72.jpg')\n",
    "\n",
    "#segmented_img=extract_Exudates(original_img)\n",
    "\n",
    "num=11\n",
    "image = image_path + images[num]\n",
    "ex_mask = EX_mask_path + EX_masks[num]\n",
    "se_mask = SE_mask_path + SE_masks[num]\n",
    "img = cv2.imread(image)\n",
    "mask_ex = cv2.imread(ex_mask)\n",
    "mask_se = cv2.imread(se_mask)\n",
    "segmented_img=extract_Exudates(img)\n",
    "plot(mask_ex)\n",
    "plot(segmented_img)\n",
    "x0,x1, ex_segmented_img=segment(img,segmented_img)\n",
    "mask_ex = cv2.cvtColor(mask_ex, cv2.COLOR_BGR2GRAY)\n",
    "ret,mask_ex = cv2.threshold(mask_ex,10,255,cv2.THRESH_BINARY)\n",
    "#plot(img,\"rbg\")\n",
    "\n",
    "print(len(x0))\n",
    "print(len(x1))\n",
    "plot(ex_segmented_img)\n",
    "\n",
    "print(evaluation(ex_segmented_img,mask_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bQaWU9M5R7I4",
    "outputId": "09758ca9-fcba-4930-f8ac-df2e25bea6bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame()\n",
    "train_labels = [] \n",
    "\n",
    "for img_number in range(len(images)):\n",
    "    # Read Image and Mask\n",
    "    image = image_path + images[img_number]\n",
    "    ex_mask = EX_mask_path + EX_masks[img_number]\n",
    "    se_mask = SE_mask_path + SE_masks[img_number]\n",
    "    img = cv2.imread(image)\n",
    "    mask_ex = cv2.imread(ex_mask)\n",
    "    mask_se = cv2.imread(se_mask)\n",
    "    originalImage = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    print(img_number,\": OriginalImage\")\n",
    "    plot(originalImage,\"BrBG\")\n",
    "    #Load the mask\n",
    "    im_mask_se = cv2.cvtColor(mask_se, cv2.COLOR_BGR2GRAY)\n",
    "    th, im_mask_se = cv2.threshold(im_mask_se, 10, 255, cv2.THRESH_BINARY)\n",
    "    print(img_number,\": mask\")\n",
    "    plot(im_mask_se)\n",
    "    im_mask_ex = cv2.cvtColor(mask_ex, cv2.COLOR_BGR2GRAY)\n",
    "    th, im_mask_ex = cv2.threshold(im_mask_ex, 10, 255, cv2.THRESH_BINARY)\n",
    "    print(img_number,\": mask\")\n",
    "    plot(im_mask_ex)\n",
    "    # segment the hard exudates\n",
    "    lesions_segmented = extract_Exudates(img)\n",
    "    print(img_number,\": lesions_segmented\")\n",
    "    plot(lesions_segmented)\n",
    "    cv2.imwrite(candidates_path + images[img_number], lesions_segmented)\n",
    "    # Get the candidates & their GLCM features with lables \n",
    "    lesions_segmented = lesions_segmented.astype(np.uint8)\n",
    "    t_features, t_labels = candidates_selection(lesions_segmented,im_mask_ex,im_mask_se)\n",
    "    train_features=train_features.append(t_features)\n",
    "    train_labels.append(t_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE0gK0fiR7I6"
   },
   "outputs": [],
   "source": [
    "# Save Training set TO EXCEL\n",
    "train_data = pd.DataFrame()\n",
    "ls=[]\n",
    "for i in range(len(train_labels)):\n",
    "  for j in range(len(train_labels[i])):\n",
    "    ls.append(train_labels[i][j])\n",
    "m = np.asarray(ls)\n",
    "\n",
    "tdata = pd.DataFrame(train_features)\n",
    "tdata['Lable'] = m\n",
    "writer = ExcelWriter('/content/drive/MyDrive/DRsegmentation/IP_ML/Training/TestingSet_Exudates.xlsx')\n",
    "tdata.to_excel(writer,'Sheet1')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3lwmPlrynYa"
   },
   "outputs": [],
   "source": [
    "#d_features=d_features.drop(index=0)\n",
    "#\n",
    "train_features = pd.read_excel(\"/content/drive/MyDrive/DRsegmentation/IP_ML/Training/TrainingSet_Exudates.xlsx\")\n",
    "m=train_features['Lable']\n",
    "train_features=train_features.drop(columns=\"Lable\")\n",
    "train_features = train_features.iloc[: , 1:]\n",
    "\n",
    "#print(train_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "N23DD87ZR7I9",
    "outputId": "ca6f0a29-1926-491f-c38a-dd2e6ff250a8"
   },
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame()\n",
    "train_y['Lable'] = m\n",
    "#train_features.drop(['Lable'],axis=1,inplace=True) #you have labels in the training set as well.\n",
    "\n",
    "train_x = train_features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y,\n",
    "                                                    stratify=train_y, \n",
    "                                                    test_size=0.25)\n",
    "\n",
    "\n",
    "x = X_train.values #returns a numpy array\n",
    "stdScaler = preprocessing.StandardScaler()\n",
    "X_train = stdScaler.fit_transform(x)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "joblib.dump(stdScaler, scaler_filename) \n",
    "\n",
    "#Loading the StdScalar\n",
    "stdScaler = joblib.load(scaler_filename) \n",
    "X_test = stdScaler.transform(X_test)\n",
    "\n",
    "\n",
    "#Training the Classifier\n",
    "mymodel=train(\"RF\",X_train,y_train)\n",
    "acc,test_pred = predict(mymodel,X_test,y_test)\n",
    "print (\"Accuracy = \", acc)\n",
    "CM_plot(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "AQdjq4InvbOv",
    "outputId": "44edef92-eb17-4b9b-dd85-8ae4c0a4881a"
   },
   "outputs": [],
   "source": [
    "tst_features = pd.read_excel(\"/content/drive/MyDrive/DRsegmentation/IP_ML/Training/TestingSet_Exudates.xlsx\")\n",
    "#d_features=d_features.drop(index=0)\n",
    "tst_features = tst_features.iloc[: , 1:]\n",
    "tst_lable = tst_features['Lable']\n",
    "tst_features=tst_features.drop(columns=\"Lable\")\n",
    "\n",
    "tst = tst_features.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "tst_x = min_max_scaler.fit_transform(tst)\n",
    "tst_x = pd.DataFrame(tst_x)\n",
    "acc,test_pred = predict(mymodel,tst_x,tst_lable)\n",
    "print (\"Accuracy = \", acc)\n",
    "CM_plot(tst_lable, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7HCEr-rPyt0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vx-BVDgSpaDe"
   },
   "outputs": [],
   "source": [
    "def segment(img):\n",
    "  segmented_img=extract_RedLesions(img)\n",
    "  segmented_img=candidates_extraction_for_inference(mymodel,img,segmented_img)\n",
    "  plot(segmented_img)\n",
    "\n",
    "  return segmented_img\n",
    "ig= cv2.imread('/content/drive/MyDrive/DRsegmentation/HEDNet_cGAN/data/OriginalImages/TestingSet/IDRiD_69.jpg')\n",
    "segment(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISbfnDn9q6V9"
   },
   "outputs": [],
   "source": [
    "filename = '/content/drive/MyDrive/DRsegmentation/IP_ML/Training/red_RF_model.sav'\n",
    "#pickle.dump(mymodel, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "acc,test_pred = predict(loaded_model,X_test,y_test)\n",
    "print (\"Accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exudates_Segmentation1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
